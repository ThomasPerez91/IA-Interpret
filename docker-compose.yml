services:
  ia_frontend:
    image: node:22-alpine
    container_name: ia_frontend
    working_dir: /app
    env_file:
      - ./.env
    volumes:
      - ./frontend:/app
      - ia_frontend_node_modules:/app/node_modules
    ports:
      - "5173:5173"
    command: >
      sh -c "
        npm install -g pnpm &&
        pnpm install &&
        pnpm run dev --host 0.0.0.0 --port 5173 --strictPort
      "
    networks:
      - ia_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:5173"]
      interval: 10s
      timeout: 3s
      retries: 5

  ia_frontend_prod:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: ia_frontend_prod
    ports:
      - "8081:80"
    networks:
      - ia_network
    restart: unless-stopped
    depends_on:
      ia_backend:
        condition: service_healthy

  ia_backend:
    container_name: ia_backend
    build:
      context: ./backend
    env_file:
      - ./backend/.env
      - ./.env
    volumes:
      - ./backend:/app
      - ia_backend_logs:/app/logs
      - ia_shared_uploads:/tmp/uploads    # ⬅️ volume partagé
    ports:
      - "5001:5000"
    networks:
      - ia_network
    restart: unless-stopped
    depends_on:
      ia_redis:
        condition: service_healthy
      ia_mongo:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  ia_worker:
    container_name: ia_worker
    build:
      context: ./backend
    env_file:
      - ./backend/.env
      - ./.env
    volumes:
      - ./backend:/app
      - ia_shared_uploads:/tmp/uploads    # ⬅️ même chemin que backend
    command: ["celery", "-A", "app.celery_app.celery_app", "worker", "--loglevel=INFO"]
    networks:
      - ia_network
    restart: unless-stopped
    depends_on:
      ia_redis:
        condition: service_healthy
      ia_mongo:
        condition: service_healthy

  ia_redis:
    container_name: ia_redis
    image: redis:8-alpine
    volumes:
      - ia_redis_data:/data
    networks:
      - ia_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 10

  ia_mongo:
    container_name: ia_mongo
    image: mongo:4
    volumes:
      - ia_mongo_data:/data/db
      - ./mongo-init:/docker-entrypoint-initdb.d:ro
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
      MONGO_INITDB_DATABASE: ${MONGO_DB_NAME}
    ports:
      - "127.0.0.1:27017:27017"
    networks:
      - ia_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 10

  ia_flower:
    image: python:3.11-slim
    container_name: ia_flower
    env_file:
      - ./.env
      - ./backend/.env
    volumes:
      - ./backend:/app
    working_dir: /app
    depends_on:
      - ia_redis
    ports:
      - "5555:5555"
    command: >
      sh -c "
        pip install --no-cache-dir -r requirements.txt &&
        pip install flower &&
        celery -A app.celery_app.celery_app flower
          --port=5555
          --broker=${REDIS_URL}
          --url_prefix=/flower
          --basic_auth=${FLOWER_USER}:${FLOWER_PASSWORD}
      "
    networks:
      - ia_network
    restart: unless-stopped

  hadoop-namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    hostname: hadoop-namenode
    container_name: hadoop-namenode
    platform: linux/amd64
    environment:
      - CLUSTER_NAME=iahadoopcluster
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000
      - HDFS_CONF_dfs_replication=1
      - HDFS_NAMENODE_HTTP_ADDRESS=hadoop-namenode:9870
      - HADOOP_NAMENODE_OPTS=-Dhadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory
    ports:
      - "9870:9870"
      - "9001:9000"
    volumes:
      - ia_hadoop_namenode:/hadoop/dfs/name
    networks:
      - ia_network
    restart: unless-stopped

  hadoop-datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    hostname: hadoop-datanode
    container_name: hadoop-datanode
    platform: linux/amd64
    environment:
      - CLUSTER_NAME=iahadoopcluster
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000
    depends_on:
      - hadoop-namenode
    volumes:
      - ia_hadoop_datanode:/hadoop/dfs/data
    networks:
      - ia_network
    restart: unless-stopped

  spark_master:
    image: bitnami/spark:latest
    hostname: sparkmaster
    container_name: spark_master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080"
      - "7077:7077"
    networks:
      - ia_network
    restart: unless-stopped

  spark_worker:
    image: bitnami/spark:latest
    hostname: sparkworker
    container_name: spark_worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://sparkmaster:7077
      - SPARK_WORKER_MEMORY=3G
      - SPARK_WORKER_CORES=2
    depends_on:
      - spark_master
    networks:
      - ia_network
    restart: unless-stopped

volumes:
  ia_redis_data:
  ia_mongo_data:
  ia_backend_logs:
  ia_frontend_node_modules:
  ia_hadoop_namenode:
  ia_hadoop_datanode:
  ia_shared_uploads:      # ⬅️ volume nommé pour les uploads partagés

networks:
  ia_network:
    driver: bridge
